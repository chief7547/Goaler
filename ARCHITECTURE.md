# Goaler 프로젝트 아키텍처

이 문서는 Goaler 프로젝트의 핵심 아키텍처, 설계 원칙, 그리고 개발 워크플로우를 설명합니다.

## 0. 개발 접근 전략: 핵심 로직을 먼저 탄탄하게

이 프로젝트는 “대화만으로 목표를 정의하고 완성할 수 있는가?”라는 질문에서 시작했습니다. 그래서 UI나 데이터베이스를 붙이기 전에, **목표를 단계별로 조립하는 비즈니스 로직**을 TDD로 먼저 만들고 충분히 검증했습니다. 이렇게 해 두니, 나중에 챗봇이 GPT를 통해 어떤 메시지를 보내더라도 결국 믿고 맡길 수 있는 코어가 생겼습니다.

## 1. 핵심 철학: 대화형 목표 설정

초기 `VIBECODE_ENTRY.md`의 인터뷰 방식은 정적인 질문/답변으로 구성되어 복잡하고 유연한 목표 설정을 구현하기에 한계가 있었습니다.

따라서, 우리는 사용자와의 자연스러운 대화를 통해 목표를 구체화하고, 지표를 추가/수정하며, 동기를 부여하는 **대화형 목표 설정(Conversational Goal-Setting)** 방식을 핵심 철학으로 채택했습니다. 이 방식은 LLM의 Function Calling(Tool-use) 능력을 기반으로 하며, 사용자가 복잡한 폼을 채울 필요 없이 AI 코치와 대화하듯 목표를 설정하는 경험을 제공합니다.

## 2. 주요 구성 요소 (`core` 디렉토리)

대화형 목표 설정을 구현하기 위한 핵심 로직은 `core` 디렉토리 안에 캡슐화되어 있습니다.

- **`core/agent.py` (`GoalSettingAgent`):**
  - 전체 대화 과정을 오케스트레이션하는 **총괄 지휘자**입니다.
  - `StateManager`를 소유하여 대화의 '상태'를 관리합니다.
  - `create_goal`, `add_metric` 등 LLM이 호출할 수 있는 실제 비즈니스 로직을 메소드로 포함합니다.

- **`core/state_manager.py` (`StateManager`):**
  - 대화가 진행되는 동안 사용자의 목표 설정 내용을 임시로 저장하는 **단기 기억 장치**입니다.
  - 각 대화별로 상태를 분리하여 관리하며, 대화가 완료되면 상태를 삭제합니다.
  - 현재는 메모리 내 딕셔너리로 구현되어 있으나, 향후 Redis 등으로 확장될 수 있습니다.

- **`core/llm_prompt.py`:**
  - LLM 에이전트의 행동을 정의하는 **지시문(Instruction)과 도구(Tool) 명세서**입니다.
  - `SYSTEM_PROMPT`는 LLM의 페르소나, 역할, 규칙(예: 모호할 경우 되묻기)을 정의합니다.
  - `create_goal` 등의 함수 시그니처는 LLM에게 어떤 도구를 사용할 수 있는지 알려주는 API 계약(Contract) 역할을 합니다.

## 3. 대화형 목표 설정 워크플로우

1.  **사용자 입력:** 사용자가 "새로운 목표를 만들고 싶어"와 같이 대화를 시작합니다.
2.  **LLM 의도 파악:** LLM은 `SYSTEM_PROMPT`와 함수 명세를 바탕으로 사용자의 의도를 파악합니다. (예: `create_goal` 함수 호출 필요)
3.  **함수 호출 (Function Calling):** LLM은 텍스트 대신, 실행해야 할 함수(예: `agent.create_goal(...)`)를 특정 형식으로 반환합니다.
4.  **에이전트 실행:** 애플리케이션은 LLM의 함수 호출 요청을 받아, `GoalSettingAgent`의 해당 메소드를 실행합니다.
5.  **상태 변경:** 에이전트의 메소드는 `StateManager`를 통해 현재 대화의 상태를 변경(생성, 수정)합니다.
6.  **LLM 응답 생성:** 에이전트는 실행 결과를 바탕으로 LLM에게 다음 응답 생성을 요청합니다. (예: "목표가 생성되었습니다. 어떤 지표를 추가할까요?")
7.  **응답 및 반복:** LLM의 응답이 사용자에게 전달되고, 사용자가 목표 설정을 완료할 때까지 위 과정이 반복됩니다.

## 4. 개발 및 테스트 전략

- **테스트 주도 개발 (TDD):** `core` 디렉토리의 모든 기능은 TDD 방식으로 개발됩니다. `tests/test_core.py`에 실패하는 테스트를 먼저 작성하고, 이를 통과시키는 코드를 `core`에 구현합니다.
- **단위 테스트:** 모든 에이전트의 메소드는 각 기능이 독립적으로 정확히 동작하는지 검증하는 단위 테스트를 가져야 합니다.
- **CI 연동:** 모든 테스트는 `pytest`를 통해 실행되며, GitHub Actions CI 파이프라인에 통합되어 코드 변경 시 항상 자동 검증됩니다.

## 5. GPT 연동 현황과 교훈

- **현재 상태:** `GOALER_USE_MOCK=false`로 실행하면 GPT 모델이 실제로 `create_goal → add_metric → set_motivation → finalize_goal` 순서로 함수를 호출합니다. 메트릭 정보를 여러 형식으로 보내도 `GoalSettingAgent`가 알아서 정리한 뒤 상태를 갱신합니다.
- **Mock 모드:** 기본값은 mock 모드입니다. 덕분에 네트워크가 막혀 있어도 언제든지 흐름을 시연하거나 테스트할 수 있습니다.
- **교훈:** 초기에 다른 모델(Gemini 등)을 검토했지만 라이브러리 안정성이 떨어졌습니다. 반면 OpenAI SDK는 툴 호출 포맷만 정확히 맞추면 안정적으로 응답을 반환하므로, 현재 구조는 GPT 계열 모델을 전제로 설계되어 있습니다.

## 6. 앞으로의 진화 방향

1. **경험 확장:** CLI 기반 데모를 웹/모바일 UI나 메시징 챗봇으로 옮겨 사용자가 목표 카드를 시각적으로 확인할 수 있게 만듭니다.
2. **지속 저장:** 지금은 인메모리 상태이므로, 목표를 DB나 파일에 저장해 다시 접속했을 때 이어서 대화할 수 있도록 합니다.
3. **코칭 콘텐츠 강화:** 목표 유형별 질문 템플릿, 행동 제안, 주간 피드백 루틴 등을 추가하면 “코치”라는 색깔이 더 선명해집니다.
4. **자동 리마인더:** 캘린더·슬랙·문자 등과 연동해 사용자가 정한 측정 주기에 맞춰 체크인을 요청하도록 확장합니다.
